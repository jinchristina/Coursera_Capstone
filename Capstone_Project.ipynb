{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Capstone Project for IBM Data Science"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Introduction"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This capstone project aims to find the key features of popular songs and therefore be able to predict if a song will be popular or not based on its features. Given a dataset of about 19000 songs from Spotify, we are looking at each song's features and seeing how that plays an effect on its popularity. This information will be helpful to new artists looking to gain fame and also songwriters to see what features are desireable in popular songs. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The song dataset is provided by Kaggle. This target variable is popularity (song_popularity) which is a score from 0 to 100. This dataset with its variables was taken from Spotify. There a total of 15 variables in the dataset, of which 10 (bolded) will be used to determine the popularity of the song. \n<ul>\n    <li> song_name: The name of the song.</li>\n    <li> song_popularity: Song ratings of spotify audience.</li>\n    <li> song_duration_ms: The duration of the track in milliseconds.</li>\n    <li> <strong> acousticness</strong>: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.</li>\n    <li> <strong> danceability</strong>: Danceability describes how suitable a track is for dancing. A value of 0.0 is least danceable and 1.0 is most danceable.</li>\n    <li> <strong> energy</strong>: A perceptual measure of intensity and activity on a scale from 0.0 to 1.0. </li>\n    <li> <strong> instrumentalness</strong>: A confidence measure from 0.0 to 1.0 of whether the track is instrumental. 1.0 represents high confidence the track is instrumental.</li>\n    <li> <strong> key</strong>: The estimated overall key of the track. E.g. 0 = C, 1 = C\u266f/D\u266d, 2 = D, and so on. If no key was detected, the value is -1.</li>\n    <li> <strong> liveness</strong>: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.</li>\n    <li> <strong> loudness</strong>: The overall loudness of a track in decibels (dB). Values typical range between -60 and 0 db.</li>\n    <li> <strong> audio_mode</strong>: Mode indicates the modality (major or minor) of a track. Major is represented by 1 and minor is 0.</li>\n    <li> speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values below 0.33 most likely represent music and other non-speech-like tracks.</li>\n    <li> <strong> tempo</strong>: The overall estimated tempo of a track in beats per minute (BPM).</li>\n    <li>time_signature: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).</li>\n    <li> <strong> audio_valence</strong>: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive, while tracks with low valence sound more negative .</li>\n</ul>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Methodology"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Data Transformation"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The target variable, <strong>song_popularity</strong>, is a continuous variable that ranges from a value of 0 to 100. But this analysis is not to find the specific rating a song will receive but more focused on finding if a song will be popular based on this features. So the target variable will be transformed to a categorical variable. For the purpose of this analysis, we will assume songs that received a score of 70 or higher is \"popular\" and song with a lower score are not. So a new varaible called <strong>popularity</strong> will be the new target variable where '1 = popular' and '0 = not popular'."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Data Cleanup"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As mentioned above, not all variables given in the dataset were used for creating the model. Song_name and song_duration_ms were dropped because they are descriptive variables that do not add value to the model. Songs with time_signature of value 4 were only used and there rest were dropped because 95% of songs were in 4 beats per measure and it is rare to find songs in other beat. Songs with speechiness values greater than or equal to 0.34 were also dropped as values below 0.33 most likely represent music and other non-speech-like tracks. That leaves 16,958 rows of data to use."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Exploratory Data Analysis"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We started by visualizing the data split into two groups, popular songs and unpopular songs. By visualizing the distribution of each feature for the two group, it seemed as if there were no significant differences between the two. However, after running statistical tests on the features, we found something different. By running z-tests on each of the features, we found that there was a significant different between the popular and unpopular songs for every feature. We also found that there was a significant correlation between each of the features and our target variable popularity. \n\nThe results of the statistical analysis is listed in the table below. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "| Dependent Variable | Z-test (p value) | Correlation |\n|---------------|----|-------|\n| Instrumentalness| 6.46163e-89 |  -0.15175   |\n| Acousticness| 1.60306e-37 |  -0.09784   |\n| Liveness | 7.81709e-05 |  -0.03032   |\n| Audio_mode | 5.86861e-04 |  -0.02639   |\n| Audio_valence | 2.96481e-03 |  -0.02281   |\n| Tempo | 2.44459e-02 |  -0.01728   |\n| Key | 3.38594e-02 |  -0.01629   |\n| Energy | 4.33088e-08 |   0.04202   |\n| Danceability | 3.71593e-59 |   0.12360   |\n| Loudness | 2.79661e-84 |   0.14774   |"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Classsification Analysis"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Before starting any analysis, the data was standardized and then split into training and testing data with 70% and 30% of the data respectively. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Four different classification analysis were done: Logistic Regression, K Nearest Neighbor, Decision Tree, and Support Vector Machine. <strong>Logistic Regression</strong> was chosen because it is suitable for this kind of problem because our target variable is binary (1-popular and 0-unpopular). <strong>K Nearest Neighbor</strong> was chosen because we saw that the popular songs' features are significantly different from the unpopular songs' features so we should be able to group similar songs together and predict the popularity of new songs. The model with the best accuracy was when k was set to 1. <strong>Decision Tree</strong> was chosen for a similar reason as K Nearest Neighbor. Since all features were observed as significant, we can train the tree to classify a song by its features. The decision tree model with best accuarcy was when the depth (number of decision steps) was set to 9. <strong>Support Vector Machine</strong> was also chosen for a similar reason as K Nearest Neighbor. Because of the significant different in features, we can find a hyperplane that divides the songs into popular and unpopular songs. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Results"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Using the four classification models listed above, we trained each one against the training dataset and then used the testing dataset to see how accurately each model was able to classify the dataset. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Listed below are the accuarcy scores from the training set. Bolded is the model that did the best. \n\n|Model|Accuracy|\n|-|-|\n|Logistic Regression| .7767 |\n|<strong>K Nearest Neighbor</strong>| .9946 |\n|Decision Tree| .8145 |\n|Support Vector Machine | .7777|\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Listed below are the accuracy scores from the testing set. Bolded is the model that did the best.\n\n|Model|Jaccard index|F1 score|\n|-|-|-|\n|Logistic Regression| .7793 | .6841|\n|<strong>K Nearest Neighbor</strong>| .8436 |.8475 |\n|Decision Tree| .7848|.7480 |\n|Support Vector Machine | .7795|.6831 |\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As we can see from the accuracy scores above, K Nearest Neighbor was able to classify the dataset the best. For the training set, it was almost able to classify the songs perfectly with an accuracy score of 99.46%. For the testing set, the model was able to predict the popularity of a song with about 84% accuracy. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Discussion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The model was able to determine if a song is popular or not based on 10 features with 84% accuracy. But there is always room for improvement. For the purpose of this project a song's popularity was assumed as a score above 70 but with a different expectation, the model could have been completely different. It would also be interesting to try to predict the popularity score as well. Also there are many features that were not included that could have played an effect on a song's popularity. It would be interesting to see how the artist or the song title plays an effect on a song's popularity. Other features like the song's release year or genre were also not considered. Adding more features can drastically change the model and how it classifies the data. \n\nA slightly different question to ask is how the trend in popular songs have changed over years. By analyzing songs popular in the 1990s v 2000s v 2010s, we can ask questions like what features or genres have become more \"trendy\" over the years, what are some features that affects popularity more now than it did before, or is there a similarity between songs that stay popular over the decades.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this capstone, we analyzed the relationship between popular songs and unpopular songs. We can conclude that there is a significant different between the features of popular songs and unpopular songs.  All 10 features we used turned out to play an effect on a song's popularity. And with those features, we trained multiple classification models and found that the K Nearest Neighbor model most accurately predicts the if a song is popular or not. New artists as well as songwriters can use this model to predict if their song will be popular or not with the general audience."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}